{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ***Hyperparameter optimization for RNN parameters***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------------------------\r\n",
    "# Download Helper and Data Files\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "output = \"helper_and_data_files.zip\"\r\n",
    "use_gdrive = False\r\n",
    "if use_gdrive:\r\n",
    "    # Download the zip file from Google Drive\r\n",
    "    import gdown\r\n",
    "    url = \"https://drive.google.com/uc?id=1JJ9pFGGlpWIVFgDudmcquVuTdtGvASvq\"\r\n",
    "    gdown.download(url, output, quiet=False)\r\n",
    "else:\r\n",
    "    # Download via Git-LFS\r\n",
    "    !curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\r\n",
    "    !sudo apt-get install git-lfs\r\n",
    "    !git lfs install\r\n",
    "    !git clone https://github.com/epfl-lasa/sliding-ds-control.git\r\n",
    "    !ln -s /content/sliding-ds-control/compliant_bumper/rnn_training/helper_and_data_files.zip .\r\n",
    "\r\n",
    "# Extract zip file\r\n",
    "import zipfile\r\n",
    "with zipfile.ZipFile(output, \"r\") as zip_ref:\r\n",
    "    zip_ref.extractall(\".\")\r\n",
    "\r\n",
    "    \r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Imports\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "import pickle\r\n",
    "from loadmat import loadmat\r\n",
    "import numpy as np\r\n",
    "from scipy.signal import decimate\r\n",
    "import IPython\r\n",
    "\r\n",
    "%tensorflow_version 2.x\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "!pip install -q keras-tuner\r\n",
    "from keras_tuner.tuners import Hyperband, BayesianOptimization\r\n",
    "\r\n",
    "%matplotlib notebook\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Load data files for training and testing**\r\n",
    "\r\n",
    "**Training Dataset**\r\n",
    "\r\n",
    "| File No.  | Description                                       |\r\n",
    "|----------:|---------------------------------------------------|\r\n",
    "| 1         | Force variations at all rows of the bumper        |\r\n",
    "| 2         | Slow force variations at all rows of the bumper   |\r\n",
    "| 8         | Impacts at top row of the bumper                  |\r\n",
    "| 9         | Impacts at middle & bottom row of the bumper      |\r\n",
    "| 10        | Force variations at all rows of the bumper        |\r\n",
    "| 11        | Force variations at all rows of the bumper        |\r\n",
    "\r\n",
    "**Testing Dataset**\r\n",
    "\r\n",
    "| File No.  | Description                                       |\r\n",
    "|----------:|---------------------------------------------------|\r\n",
    "| 2         | Slow force variation                              |\r\n",
    "| 4         | High force impacts                                |\r\n",
    "| 5         | Low force impacts                                 |\r\n",
    "| 6         | Random force inputs (No impacts)                  |\r\n",
    "| 7         | Pull dataset                                      |"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_files = [\"calibration_struct{:d}.mat\".format(i) for i in [1, 8, 9, 2, 10, 11]]\r\n",
    "test_files  = [\"calibration_struct{:d}.mat\".format(i) for i in [2, 4, 6, 7, 5]]\r\n",
    "n_history = 5\r\n",
    "\r\n",
    "tuner_type = \"hyperband\"\r\n",
    "# tuner_type = \"bayesian\"\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Lambda functions for data extractions\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "get_X = lambda tmp: np.vstack((\r\n",
    "    tmp[\"Fx_measured\"],\r\n",
    "    tmp[\"Fy_measured\"],\r\n",
    "    tmp[\"Fz_measured\"],\r\n",
    "    tmp[\"Mx_measured\"],\r\n",
    "    tmp[\"My_measured\"],\r\n",
    "    tmp[\"Mz_measured\"],\r\n",
    ")).T\r\n",
    "\r\n",
    "get_y = lambda tmp: np.vstack((\r\n",
    "    tmp[\"Fx_applied\"],\r\n",
    "    tmp[\"Fy_applied\"],\r\n",
    "    tmp[\"Mz_applied\"],\r\n",
    ")).T\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Load Data\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "X = np.empty((0,6))\r\n",
    "y = np.empty((0,3))\r\n",
    "for filename in train_files:\r\n",
    "    print(f\"Loading {filename} ...\")\r\n",
    "    data = loadmat(filename)\r\n",
    "    data = data[\"training_data_struct\"]\r\n",
    "    for test in data.keys():\r\n",
    "        X = np.vstack((X, get_X(data[test])))\r\n",
    "        y = np.vstack((y, get_y(data[test])))\r\n",
    "\r\n",
    "X_test = {}\r\n",
    "y_test = {}\r\n",
    "for filename in test_files:\r\n",
    "    print(f\"Loading {filename} ...\")\r\n",
    "    data = loadmat(filename)\r\n",
    "    data = data[\"training_data_struct\"]\r\n",
    "    X_temp = np.empty((0,6))\r\n",
    "    y_temp = np.empty((0,3))\r\n",
    "    for test in data.keys():\r\n",
    "        X_temp = np.vstack((X_temp, get_X(data[test])))\r\n",
    "        y_temp = np.vstack((y_temp, get_y(data[test])))\r\n",
    "    X_test[filename[:-4]] = X_temp\r\n",
    "    y_test[filename[:-4]] = y_temp\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Downsample from 400Hz to 200 Hz (realworld control frequency)\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "X = decimate(X, 2, axis=0)\r\n",
    "y = decimate(y, 2, axis=0)\r\n",
    "for filename in test_files:\r\n",
    "    X_test[filename[:-4]] = decimate(X_test[filename[:-4]], 2, axis=0)\r\n",
    "    y_test[filename[:-4]] = decimate(y_test[filename[:-4]], 2, axis=0)\r\n",
    "    \r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Stack training data for RNN training\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "X_train = np.hstack([\r\n",
    "    X[i:len(X)-n_history+i] for i in range(n_history+1)\r\n",
    "])\r\n",
    "y_train = y[n_history:]\r\n",
    "\r\n",
    "print(\"Training Data with history: X =\", X_train.shape, \"; y =\", y_train.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------------------------\r\n",
    "# Model Defination\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "def build_model(hp):\r\n",
    "    inputs = keras.Input(shape=(X_train.shape[1],))\r\n",
    "\r\n",
    "    x = layers.Reshape((n_history+1, 6))(inputs)\r\n",
    "    x = layers.LSTM(hp.Int('units_LSTM', min_value = 4, max_value = 64, step = 4),\r\n",
    "                    activation=\"tanh\",\r\n",
    "                    recurrent_activation=\"sigmoid\")(x)\r\n",
    "    \r\n",
    "    x_Fx = x\r\n",
    "    for i in range(hp.Int('layers_Fx', min_value = 1, max_value = 4, step = 1)):\r\n",
    "        x_Fx = layers.Dense(\r\n",
    "            hp.Int('units_Fx_' + str(i), min_value = 4, max_value = 32, step = 2),\r\n",
    "            activation=hp.Choice('act_Fx_' + str(i), [\"relu\", \"sigmoid\", \"tanh\"])\r\n",
    "        )(x_Fx)\r\n",
    "    output_Fx = layers.Dense(1, name=\"Fx\")(x_Fx)\r\n",
    "\r\n",
    "    x_Fy = x\r\n",
    "    for i in range(hp.Int('layers_Fy', min_value = 1, max_value = 4, step = 1)):\r\n",
    "        x_Fy = layers.Dense(\r\n",
    "            hp.Int('units_Fy_' + str(i), min_value = 4, max_value = 32, step = 2),\r\n",
    "            activation=hp.Choice('act_Fy_' + str(i), [\"relu\", \"sigmoid\", \"tanh\"])\r\n",
    "        )(x_Fy)\r\n",
    "    output_Fy = layers.Dense(1, name=\"Fy\")(x_Fy)\r\n",
    "\r\n",
    "    x_Mz = x\r\n",
    "    for i in range(hp.Int('layers_Mz', min_value = 1, max_value = 4, step = 1)):\r\n",
    "        x_Mz = layers.Dense(\r\n",
    "            hp.Int('units_Mz_' + str(i), min_value = 4, max_value = 32, step = 2),\r\n",
    "            activation=hp.Choice('act_Mz_' + str(i), [\"relu\", \"sigmoid\", \"tanh\"])\r\n",
    "        )(x_Mz)\r\n",
    "    output_Mz = layers.Dense(1, name=\"Mz\")(x_Mz)\r\n",
    "\r\n",
    "    model = keras.Model(\r\n",
    "        inputs=inputs,\r\n",
    "        outputs=[output_Fx, output_Fy, output_Mz],\r\n",
    "        name=\"Bumper\",\r\n",
    "    )\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        loss=tf.keras.losses.Huber(),\r\n",
    "        # loss=keras.losses.MeanSquaredError(),\r\n",
    "        loss_weights=[1.0, 1.0, 1.0],\r\n",
    "        optimizer=keras.optimizers.RMSprop(),\r\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError()],\r\n",
    "    )\r\n",
    "    return model\r\n",
    "\r\n",
    "# Clear Output fix\r\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\r\n",
    "    def on_train_end(*args, **kwargs):\r\n",
    "        IPython.display.clear_output(wait = True)\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Setup Tuner\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "if tuner_type == \"hyperband\":\r\n",
    "    tuner = Hyperband(\r\n",
    "        build_model,\r\n",
    "        objective=\"val_loss\", \r\n",
    "        max_epochs=20,\r\n",
    "        executions_per_trial=3,\r\n",
    "        directory='nn_hyperparam',\r\n",
    "        project_name='Bumper_hp_hyperband', \r\n",
    "        overwrite=True,\r\n",
    "    )\r\n",
    "elif tuner_type == \"bayesian\":\r\n",
    "    tuner = BayesianOptimization(\r\n",
    "        build_model,\r\n",
    "        objective=\"val_loss\", \r\n",
    "        max_trials=200,\r\n",
    "        num_initial_points=10,\r\n",
    "        executions_per_trial=5,\r\n",
    "        directory='nn_hyperparam',\r\n",
    "        project_name='Bumper_hp_bayesian',\r\n",
    "        overwrite=True,\r\n",
    "    )\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Run Tuner\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "tuner.search(X_train, [y_train[:,i] for i in range(3)],\r\n",
    "             validation_split=0.2,\r\n",
    "             batch_size=2048,\r\n",
    "             epochs=50,\r\n",
    "             verbose=2,\r\n",
    "             callbacks=[ClearTrainingOutput()])\r\n",
    "\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "# Save tuner\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "with open(f\"nn_hyperparam/{tuner_type}_tuner.pkl\", \"wb\") as f:\r\n",
    "    pickle.dump(tuner, f)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------------------------\r\n",
    "# Get the optimal hyperparameters\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "with open(f\"nn_hyperparam/{tuner_type}_tuner.pkl\", \"rb\") as f:\r\n",
    "    tuner = pickle.load(f)\r\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=10)\r\n",
    "\r\n",
    "string = \"\"\"\r\n",
    "================================================================================\r\n",
    "    units_LSTM = {units_LSTM}\r\n",
    "    --------------------------------------------\r\n",
    "    layers_Fx = {layers_Fx}\r\n",
    "        0 => {units_Fx_0:2d} , {act_Fx_0}\r\n",
    "        1 => {units_Fx_1:2d} , {act_Fx_1}\r\n",
    "        2 => {units_Fx_2:2d} , {act_Fx_2}\r\n",
    "        3 => {units_Fx_2:2d} , {act_Fx_3}\r\n",
    "    --------------------------------------------\r\n",
    "    layers_Fy = {layers_Fy}\r\n",
    "        0 => {units_Fy_0:2d} , {act_Fy_0}\r\n",
    "        1 => {units_Fy_1:2d} , {act_Fy_1}\r\n",
    "        2 => {units_Fy_2:2d} , {act_Fy_2}\r\n",
    "        3 => {units_Fy_3:2d} , {act_Fy_3}\r\n",
    "    --------------------------------------------\r\n",
    "    layers_Mz = {layers_Mz}\r\n",
    "        0 => {units_Mz_0:2d} , {act_Mz_0}\r\n",
    "        1 => {units_Mz_1:2d} , {act_Mz_1}\r\n",
    "        2 => {units_Mz_2:2d} , {act_Mz_2}\r\n",
    "        3 => {units_Mz_3:2d} , {act_Mz_3}\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "for hps in best_hps:\r\n",
    "    if hps.values['units_LSTM'] < 30:\r\n",
    "        print(string.format(**hps.values))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ------------------------------------------------------------------------------\r\n",
    "# Show results from best hyperparameter model\r\n",
    "# ------------------------------------------------------------------------------\r\n",
    "with open(f\"nn_hyperparam/{tuner_type}_tuner.pkl\", \"rb\") as f:\r\n",
    "    tuner = pickle.load(f)\r\n",
    "best_model = tuner.get_best_models(num_models=10)[1]\r\n",
    "\r\n",
    "stats = \"| {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} |\\n\".format(\r\n",
    "    \"Test Name\", \"Force Name\", \"mean\", \"std\", \"min\", \"max\", \"rms\"\r\n",
    ")\r\n",
    "stats += \"| {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} | {:^10s} |\\n\".format(*[\"---\"]*7)\r\n",
    "stats_format = \"| {:^10s} | {:^10s} | {mean:>10.4f} | {std:>10.4f} | {min:>10.4f} | {max:>10.4f} | {rms:>10.4f} |\\n\"\r\n",
    "stats_dict = {}\r\n",
    "err_dict = {}\r\n",
    "\r\n",
    "out_name = [\"Fx\", \"Fy\", \"Mz\"]\r\n",
    "\r\n",
    "y_est = best_model.predict(X_train)\r\n",
    "stats_dict[\"Train\"] = {}\r\n",
    "err_dict[\"Train\"] = {}\r\n",
    "for i in range(2):\r\n",
    "    err = (y_train[:,i] - y_est[i].T)\r\n",
    "    err_dict[\"Train\"][out_name[i]] = err\r\n",
    "    stats_dict[\"Train\"][out_name[i]] = {\r\n",
    "        'mean':np.mean(err),\r\n",
    "        'std':np.std(err),\r\n",
    "        'min':np.min(err),\r\n",
    "        'max':np.max(err),\r\n",
    "        'rms':np.sqrt(np.mean(err**2)),\r\n",
    "    }\r\n",
    "    stats += stats_format.format(\"Train\", out_name[i], **stats_dict[\"Train\"][out_name[i]])\r\n",
    "\r\n",
    "for k in X_test:\r\n",
    "    X_tester = np.hstack([\r\n",
    "        X_test[k][i:len(X_test[k])-n_history+i] for i in range(n_history+1)\r\n",
    "    ])\r\n",
    "    y_tester = y_test[k][n_history:]\r\n",
    "    y_est = best_model.predict(X_tester)\r\n",
    "    \r\n",
    "    stats_dict[\"Test \" + k[-1]] = {}\r\n",
    "    err_dict[\"Test \" + k[-1]] = {}\r\n",
    "    for i in range(2):\r\n",
    "        err = (y_tester[:,i] - y_est[i].T)\r\n",
    "        err_dict[\"Test \" + k[-1]][out_name[i]] = err\r\n",
    "        stats_dict[\"Test \" + k[-1]][out_name[i]] = {\r\n",
    "            'mean':np.mean(err),\r\n",
    "            'std':np.std(err),\r\n",
    "            'min':np.min(err),\r\n",
    "            'max':np.max(err),\r\n",
    "            'rms':np.sqrt(np.mean(err**2)),\r\n",
    "        }\r\n",
    "        stats += stats_format.format(\"Test \" + k[-1], out_name[i], **stats_dict[\"Test \" + k[-1]][out_name[i]])"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testnames = stats_dict.keys()\r\n",
    "forcenames = [\"Fx\", \"Fy\", \"Mz\"]\r\n",
    "colors = [\"#d95f02\", \"#1b9e77\", \"#7570b3\"]\r\n",
    "n = len(forcenames)\r\n",
    "m = len(testnames)\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "plots = []\r\n",
    "for i, forcename in enumerate(forcenames):\r\n",
    "    ymean = []\r\n",
    "    yerr = []\r\n",
    "    ymin = []\r\n",
    "    ymax = []\r\n",
    "    for testname in testnames:\r\n",
    "        ymean.append(stats_dict[testname][forcename][\"mean\"])\r\n",
    "        yerr.append(stats_dict[testname][forcename][\"std\"])\r\n",
    "        ymin.append(stats_dict[testname][forcename][\"min\"])\r\n",
    "        ymax.append(stats_dict[testname][forcename][\"max\"])\r\n",
    "\r\n",
    "    plots.append(plt.errorbar(\r\n",
    "        x=np.arange(m)*n + i*0.6,\r\n",
    "        y=ymean,\r\n",
    "        yerr=yerr,\r\n",
    "        linestyle='None',\r\n",
    "        marker='s',\r\n",
    "        markersize=4,\r\n",
    "        color=colors[i],\r\n",
    "        capsize=5,\r\n",
    "        label=forcename\r\n",
    "    ))\r\n",
    "    \r\n",
    "    plt.plot(\r\n",
    "        np.arange(m)*n + i*0.6,\r\n",
    "        ymin,\r\n",
    "        linestyle='None',\r\n",
    "        marker=\"2\",\r\n",
    "        markersize=8,\r\n",
    "        color=colors[i]\r\n",
    "    )\r\n",
    "    plt.plot(\r\n",
    "        np.arange(m)*n + i*0.6,\r\n",
    "        ymax,\r\n",
    "        linestyle='None',\r\n",
    "        marker=\"1\",\r\n",
    "        markersize=8,\r\n",
    "        color=colors[i]\r\n",
    "    )\r\n",
    "\r\n",
    "plt.legend(plots, forcenames)\r\n",
    "plt.xticks(np.arange(0, n*m, n) + 0.6, testnames)\r\n",
    "plt.ylabel(\"Error in Forces/Moments\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}